{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conventions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name\n",
       "0  conventions"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", convention_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>notnull</th>\n",
       "      <th>dflt_value</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>party</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>night</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>speaker</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>speaker_count</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>time</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>text</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>text_len</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>file</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cid           name     type  notnull dflt_value  pk\n",
       "0    0          party     TEXT        0       None   0\n",
       "1    1          night  INTEGER        0       None   0\n",
       "2    2        speaker     TEXT        0       None   0\n",
       "3    3  speaker_count  INTEGER        0       None   0\n",
       "4    4           time     TEXT        0       None   0\n",
       "5    5           text     TEXT        0       None   0\n",
       "6    6       text_len     TEXT        0       None   0\n",
       "7    7           file     TEXT        0       None   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"PRAGMA table_info(conventions);\", convention_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541\n",
      "[['Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20. Read the full transcript of the event here. Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', 'Democratic'], ['I’m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order. Welcome all to our final session of this historic and memorable convention. We’ve called the 48th Quadrennial Democratic National Convention to order.', 'Democratic']]\n"
     ]
    }
   ],
   "source": [
    "convention_data = []\n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "    '''\n",
    "    SELECT text, party\n",
    "    FROM conventions\n",
    "    WHERE party != 'Other';\n",
    "    '''\n",
    ")\n",
    "\n",
    "for row in query_results:\n",
    "    convention_data.append([row[0], row[1]])\n",
    "\n",
    "print(len(convention_data))\n",
    "print(convention_data[:2])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Every generation before us has had to fight for what they believe in and it’s just our turn now. Jack G.: ( 01:02:03 )  I was proud when I saw the demonstrations that were going on across the country.',\n",
       "  'Democratic'],\n",
       " ['They’re not bad folks, folks. But guess what? They’re not competition for us.',\n",
       "  'Republican'],\n",
       " ['And when I finally did, he was my rock, getting me through those hours, weeks, months of unspeakable pain and unending surgeries. He was my anchor as I relearned to walk, helping me through every step and every stumble. Our military spouses hold their families together, praying for their loved ones safety, wherever they’re deployed and serving as caregivers to our disabled service members. And then picking up the pieces and starting again, whenever the next tour or the next war arises, Joe Biden understands the sacrifices because he’s made them himself. When his son Beau deployed to Iraq, his burden was also shouldered by his family. Joe knows the fear military families live because he’s felt that dread of never knowing if your deployed loved one is safe. He understands their bravery because he has had to muster that same strength. Every hour of every day Beau was overseas. That’s the kind of leader our service members deserve.',\n",
       "  'Democratic'],\n",
       " ['So let me tell you about my friend Joe Biden. 12 years ago, when I began my search for a vice president, I didn’t know I’d ended up finding a brother. Joe and I come from different places, different generations, but what I quickly came to admire about Joe Biden is his resilience, born of too much struggle. His empathy, born a too much grief. Joe is a man who learned early on to treat every person he meets with respect and dignity. Living by the words his parents taught him. No one’s better than you, Joe, but you’re better than nobody.',\n",
       "  'Democratic'],\n",
       " ['So Jordan, if President Trump was standing right there, what would you say to him today about right to try.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2020 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mammajamma/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/mammajamma/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10740\n",
      "[['Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20.', 'Democratic'], ['Read the full transcript of the event here.', 'Democratic'], ['Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', 'Democratic'], ['I’m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order.', 'Democratic'], ['Welcome all to our final session of this historic and memorable convention.', 'Democratic']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "conv_sent_data = []\n",
    "\n",
    "for speech, party in convention_data:\n",
    "    sentences = sent_tokenize(speech)\n",
    "    for sent in sentences:\n",
    "        conv_sent_data.append([sent, party])\n",
    "\n",
    "print(len(conv_sent_data))\n",
    "print(conv_sent_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I grew up in Grapevine, Texas, a town that my great grandfather was the first black man to settle as a sharecropper in 1896.',\n",
       "  'Republican'],\n",
       " ['And he’ll solve them in a way that puts working people first.',\n",
       "  'Democratic'],\n",
       " ['Our agenda is based on freedom.', 'Republican'],\n",
       " ['You are making America safe again.', 'Republican'],\n",
       " ['We worshiped our mother.', 'Democratic']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10081\n",
      "[('millions women men flooded streets', 'Democratic'), ('marie trust trust know word', 'Democratic'), ('remember scared', 'Democratic'), ('put opportunity zones trump tax bill would drive investment communities decades', 'Republican'), ('storm', 'Democratic')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mammajamma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "clean_conv_sent_data = []\n",
    "\n",
    "for idx, (sent, party) in enumerate(conv_sent_data):\n",
    "    # lowercase + tokenize on whitespace\n",
    "    tokens = sent.lower().split()\n",
    "    \n",
    "    # remove punctuation + non-alpha + stopwords\n",
    "    tokens = [w for w in tokens if w.isalpha() and w not in stop_words]\n",
    "    \n",
    "    # join tokens back to string\n",
    "    cleaned_sentence = \" \".join(tokens)\n",
    "    \n",
    "    if cleaned_sentence:  # keep only non-empty\n",
    "        clean_conv_sent_data.append((cleaned_sentence, party))\n",
    "\n",
    "print(len(clean_conv_sent_data))\n",
    "print(random.choices(clean_conv_sent_data, k=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 1776 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    words = set(text.split())   # unique words in this sentence\n",
    "    ret_dict = dict()           # initialize dictionary BEFORE loop\n",
    "\n",
    "    for w in fw:\n",
    "        if w in words:\n",
    "            ret_dict[w] = True\n",
    "\n",
    "    return ret_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'america': True, 'first': True, 'freedom': True}\n"
     ]
    }
   ],
   "source": [
    "test_text = \"freedom and america first\"\n",
    "print(conv_features(test_text, feature_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"obama was the president\",feature_words)==\n",
    "       {'obama':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in clean_conv_sent_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   votes = True           Democr : Republ =     44.5 : 1.0\n",
      "                 radical = True           Republ : Democr =     29.2 : 1.0\n",
      "             enforcement = True           Republ : Democr =     20.0 : 1.0\n",
      "                 climate = True           Democr : Republ =     15.6 : 1.0\n",
      "                 sanders = True           Democr : Republ =     15.3 : 1.0\n",
      "               committee = True           Democr : Republ =     14.1 : 1.0\n",
      "                   media = True           Republ : Democr =     13.5 : 1.0\n",
      "              affordable = True           Democr : Republ =     12.4 : 1.0\n",
      "                 current = True           Democr : Republ =     11.9 : 1.0\n",
      "                freedoms = True           Republ : Democr =     11.4 : 1.0\n",
      "                  bernie = True           Democr : Republ =     10.9 : 1.0\n",
      "                 chinese = True           Republ : Democr =     10.8 : 1.0\n",
      "                 destroy = True           Republ : Democr =     10.8 : 1.0\n",
      "               democracy = True           Democr : Republ =     10.7 : 1.0\n",
      "                   china = True           Republ : Democr =     10.7 : 1.0\n",
      "                  joseph = True           Democr : Republ =     10.5 : 1.0\n",
      "                   lewis = True           Democr : Republ =     10.5 : 1.0\n",
      "                systemic = True           Democr : Republ =     10.5 : 1.0\n",
      "                     gun = True           Democr : Republ =     10.2 : 1.0\n",
      "                    isis = True           Republ : Democr =     10.1 : 1.0\n",
      "                  record = True           Republ : Democr =      9.8 : 1.0\n",
      "                  kamala = True           Democr : Republ =      9.6 : 1.0\n",
      "                    mike = True           Republ : Democr =      9.4 : 1.0\n",
      "                   elect = True           Democr : Republ =      9.1 : 1.0\n",
      "                   clean = True           Democr : Republ =      8.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "_Your observations to come._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a little bit strange to me that there are Pronouns like peoples names listed here.  I dont know that this would be information that we would want to include because those are pretty self explanatory. For example, we know that Kamala is most likely referencing Democratic, because she is a Democrat. It is interesting that Naive Bayes was so good at clearly delineating the words that represent the classes in a simingly clear and accurate way. There is considerable more aggression in the Rpublican output tahn the Democratic. I think that removing the names as an option would have provided better context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664656\n",
      "[('Mo Brooks', 'Republican', b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq'), ('Mo Brooks', 'Republican', b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6'), ('Mo Brooks', 'Republican', b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA'), ('Mo Brooks', 'Republican', b'\"The trouble with Socialism is that eventually you run out of other people\\'s money.\" - Margaret Thatcher https://t.co/X97g7wzQwJ'), ('Mo Brooks', 'Republican', b'\"The trouble with socialism is eventually you run out of other people\\'s money\" \\xe2\\x80\\x93 Thatcher. She\\'ll be sorely missed. http://t.co/Z8gBnDQUh8')]\n"
     ]
    }
   ],
   "source": [
    "print(len(results))\n",
    "\n",
    "print(results[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664155\n",
      "[['brooks joins alabama delegation voting flawed funding bill http', 'Republican'], ['brooks senate democrats allowing president give americans jobs illegals securetheborder https', 'Republican'], ['nasa square event sat stop amp hear incredible work done downtownhsv http', 'Republican'], ['trouble socialism eventually run people money margaret thatcher https', 'Republican'], ['trouble socialism eventually run people money thatcher sorely missed http', 'Republican']]\n"
     ]
    }
   ],
   "source": [
    "tweet_data = []\n",
    "\n",
    "for candidate, party, tweet in results:\n",
    "    # decode bytes to string due to the b delineation in the above output\n",
    "    if isinstance(tweet, bytes):\n",
    "        tweet = tweet.decode(\"utf-8\", errors=\"ignore\")\n",
    "    \n",
    "    # repeat cleaining process from part 1\n",
    "    tokens = [w.lower() for w in nltk.word_tokenize(tweet) if w.isalpha()] \n",
    "    tokens = [w for w in tokens if w not in stopwords.words(\"english\")]     \n",
    "    cleaned_tweet = \" \".join(tokens)                                        \n",
    "    \n",
    "    if cleaned_tweet:  \n",
    "        tweet_data.append([cleaned_tweet, party])\n",
    "\n",
    "print(len(tweet_data))\n",
    "print(tweet_data[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: despite president says people know always american values https\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: goldman sachs invested pension funds russian banks amp iraqi bonds amp single bonds fishy https\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: another pretty terrible week field woman teacher worker lgbt parent read http\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: going posting brat facts election quiz brat pack http\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: judge dismisses charges muslim new mexico compound suspects https\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: watch live https\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats rafa enjoy please reach want jaw vent https\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: weekend murfreesboro community celebrating fall festivals contest champions https\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today marks anniversary daca continue stand dreamers fight savedaca https\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: observe firepreventionweek pray path hurricane michael reminded disasters strike little warning visit https today learn prepare emergencies https\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    #estimated_party = '??' # you need to fill this in.\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    \n",
    "    # Classify using Naive Bayes\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "    features = conv_features(tweet, feature_words)\n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 2824, 'Democratic': 1551}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 3142, 'Democratic': 2485})})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the is really incorrectly categorizing Democrats as Republicans.  The True Positive rate for Repbulicans is considerably better than it is for Democrats indicating that the model is for some reason favoring placing tweets in the Republican classification. There are different result calculations that can be run with these numbers to closer examine the output including, accuracy, precision and recall but it is clear from these observations that the classifier has difficulty identifing Democratic Tweets and favors classifying them as Republican which demonstrates class imbalance. After analyzing the speeches, there were key words that were clearly designated as more Republican or Democratic with obvious ratios.  Based on the results after observing the same training on tweets rather than on speeches it seems to suggest that different training should have been applied to the twitter data. This makes sense as the way members tweet will be different than formal speeches. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
